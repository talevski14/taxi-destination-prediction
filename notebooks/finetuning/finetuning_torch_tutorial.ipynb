{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook shows how to use TimesFM with finetuning. \n",
    "\n",
    "In order to perform finetuning, you need to create the Pytorch Dataset in a proper format. The example of the Dataset is provided below.\n",
    "The finetuning code can be found in timesfm.finetuning_torch.py. This notebook just imports the methods from finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T12:08:11.987464Z",
     "start_time": "2025-09-21T12:08:01.762559Z"
    }
   },
   "source": [
    "from os import path\n",
    "from typing import Optional, Tuple, Dict\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from finetuning.finetuning_torch import FinetuningConfig, TimesFMFinetuner\n",
    "from huggingface_hub import snapshot_download\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from timesfm import TimesFm, TimesFmCheckpoint, TimesFmHparams\n",
    "from timesfm.pytorch_patched_decoder import PatchedTimeSeriesDecoder\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class MultiTimeSeriesDataset(Dataset):\n",
    "  \"\"\"Dataset for time series data compatible with TimesFM.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               series_dict: Dict[int, np.ndarray],\n",
    "               context_length: int,\n",
    "               horizon_length: int,\n",
    "               freq_type: int = 0):\n",
    "    \"\"\"\n",
    "        Initialize dataset.\n",
    "\n",
    "        Args:\n",
    "            series_dict: Time series data\n",
    "            context_length: Number of past timesteps to use as input\n",
    "            horizon_length: Number of future timesteps to predict\n",
    "            freq_type: Frequency type (0, 1, or 2)\n",
    "        \"\"\"\n",
    "    if freq_type not in [0, 1, 2]:\n",
    "      raise ValueError(\"freq_type must be 0, 1, or 2\")\n",
    "\n",
    "    self.context_length = context_length\n",
    "    self.horizon_length = horizon_length\n",
    "    self.freq_type = freq_type\n",
    "    self.samples = []\n",
    "\n",
    "    for series_id, series in series_dict.items():\n",
    "        total_length = context_length + horizon_length\n",
    "        for start_idx in range(0, len(series) - total_length + 1):\n",
    "            end_idx = start_idx + context_length\n",
    "            x_context = series[start_idx:end_idx]\n",
    "            x_future = series[end_idx:end_idx + horizon_length]\n",
    "            self.samples.append((series_id, x_context, x_future))\n",
    "\n",
    "  def __len__(self) -> int:\n",
    "    return len(self.samples)\n",
    "\n",
    "  def __getitem__(self, index: int):\n",
    "    series_id, x_context, x_future = self.samples[index]\n",
    "    x_context = torch.tensor(x_context, dtype=torch.float32)\n",
    "    x_future = torch.tensor(x_future, dtype=torch.float32)\n",
    "    input_padding = torch.zeros_like(x_context)\n",
    "    freq = torch.tensor([self.freq_type], dtype=torch.long)\n",
    "    return series_id, x_context, input_padding, freq, x_future\n",
    "\n",
    "def prepare_datasets(df: pd.DataFrame,\n",
    "                     column: str,\n",
    "                     context_length: int,\n",
    "                     horizon_length: int,\n",
    "                     train_split: float = 0.8) -> Tuple[Dataset, Dataset]:\n",
    "  \"\"\"\n",
    "    Prepare training and validation datasets from time series data.\n",
    "\n",
    "    Args:\n",
    "        df: Input time series df\n",
    "        column: Column name\n",
    "        context_length: Number of past timesteps to use\n",
    "        horizon_length: Number of future timesteps to predict\n",
    "        freq_type: Frequency type (0, 1, or 2)\n",
    "        train_split: Fraction of data to use for training\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (train_dataset, val_dataset)\n",
    "    \"\"\"\n",
    "\n",
    "  series_dict = {\n",
    "        ride_id: df[df[\"unique_id\"] == ride_id][column].values\n",
    "        for ride_id in df[\"unique_id\"].unique()\n",
    "    }\n",
    "\n",
    "  train_dict, val_dict = {}, {}\n",
    "  for sid, series in series_dict.items():\n",
    "    split_idx = int(len(series) * train_split)\n",
    "    train_dict[sid] = series[:split_idx]\n",
    "    val_dict[sid] = series[split_idx:]\n",
    "\n",
    "  train_dataset = MultiTimeSeriesDataset(train_dict, context_length, horizon_length)\n",
    "  val_dataset = MultiTimeSeriesDataset(val_dict, context_length, horizon_length)\n",
    "  return train_dataset, val_dataset\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " See https://github.com/google-research/timesfm/blob/master/README.md for updated APIs.\n",
      "Loaded PyTorch TimesFM, likely because python version is 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)].\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T12:08:12.001542Z",
     "start_time": "2025-09-21T12:08:11.994475Z"
    }
   },
   "source": [
    "def get_model(load_weights: bool = False):\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "  repo_id = \"google/timesfm-2.0-500m-pytorch\"\n",
    "  hparams = TimesFmHparams(\n",
    "      backend=device,\n",
    "      per_core_batch_size=32,\n",
    "      horizon_len=20,\n",
    "      num_layers=50,\n",
    "      use_positional_embedding=False,\n",
    "      context_len=\n",
    "      256,  # Context length can be anything up to 2048 in multiples of 32\n",
    "  )\n",
    "  tfm = TimesFm(hparams=hparams,\n",
    "                checkpoint=TimesFmCheckpoint(huggingface_repo_id=repo_id))\n",
    "\n",
    "  model = PatchedTimeSeriesDecoder(tfm._model_config)\n",
    "  if load_weights:\n",
    "    checkpoint_path = path.join(snapshot_download(repo_id), \"torch_model.ckpt\")\n",
    "    loaded_checkpoint = torch.load(checkpoint_path, weights_only=True)\n",
    "    model.load_state_dict(loaded_checkpoint)\n",
    "  return model, hparams, tfm._model_config\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T12:08:12.315742Z",
     "start_time": "2025-09-21T12:08:12.303052Z"
    }
   },
   "source": [
    "def plot_predictions(\n",
    "    model: TimesFm,\n",
    "    val_dataset: Dataset,\n",
    "    sample_idx: int = 0,\n",
    ") -> None:\n",
    "  \"\"\"\n",
    "    Plot model predictions against ground truth for a batch of validation data.\n",
    "\n",
    "    Args:\n",
    "      model: Trained TimesFM model\n",
    "      val_dataset: Validation dataset\n",
    "    \"\"\"\n",
    "  import matplotlib.pyplot as plt\n",
    "  model.eval()\n",
    "\n",
    "  series_id, x_context, x_padding, freq, x_future = val_dataset[sample_idx]\n",
    "\n",
    "  x_context = x_context.unsqueeze(0)\n",
    "  x_padding = x_padding.unsqueeze(0)\n",
    "  freq = freq.unsqueeze(0)\n",
    "  x_future = x_future.unsqueeze(0)\n",
    "\n",
    "  device = next(model.parameters()).device\n",
    "  x_context = x_context.to(device)\n",
    "  x_padding = x_padding.to(device)\n",
    "  freq = freq.to(device)\n",
    "  x_future = x_future.to(device)\n",
    "\n",
    "  with torch.no_grad():\n",
    "    predictions = model(x_context, x_padding.float(), freq)\n",
    "    predictions_mean = predictions[..., 0]\n",
    "    last_patch_pred = predictions_mean[:, -1, :]\n",
    "\n",
    "  context_vals = x_context[0].cpu().numpy()\n",
    "  future_vals = x_future[0].cpu().numpy()\n",
    "  pred_vals = last_patch_pred[0].cpu().numpy()\n",
    "\n",
    "  context_len = len(context_vals)\n",
    "  horizon_len = len(future_vals)\n",
    "\n",
    "  plt.figure(figsize=(12, 6))\n",
    "\n",
    "  plt.plot(range(context_len),\n",
    "           context_vals,\n",
    "           label=f\"Historical Data (id = {series_id})\",\n",
    "           color=\"blue\",\n",
    "           linewidth=2)\n",
    "\n",
    "  plt.plot(\n",
    "      range(context_len, context_len + horizon_len),\n",
    "      future_vals,\n",
    "      label=\"Ground Truth\",\n",
    "      color=\"green\",\n",
    "      linestyle=\"--\",\n",
    "      linewidth=2,\n",
    "  )\n",
    "\n",
    "  plt.plot(range(context_len, context_len + horizon_len),\n",
    "           pred_vals,\n",
    "           label=\"Prediction\",\n",
    "           color=\"red\",\n",
    "           linewidth=2)\n",
    "\n",
    "  plt.xlabel(\"Time Step\")\n",
    "  plt.ylabel(\"Value\")\n",
    "  plt.title(\"TimesFM Predictions vs Ground Truth\")\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  plt.show()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T12:08:12.343032Z",
     "start_time": "2025-09-21T12:08:12.329333Z"
    }
   },
   "source": [
    "def get_data(context_len: int,\n",
    "             horizon_len: int,\n",
    "             coord: str,\n",
    "             freq_type: int = 0) -> Tuple[Dataset, Dataset, any]:\n",
    "    df = pd.read_parquet(\"../../data/data_taxi_central_based.parquet\")\n",
    "    df = df[df['POLYLINE_LENGTH'] == 1266]\n",
    "\n",
    "    coord_to_drop = 'LAT' if coord == 'LON' else 'LON'\n",
    "    df = df.drop(columns=['ORIGIN_CALL', 'TAXI_ID', 'POLYLINE_LENGTH', coord_to_drop])\n",
    "    df = df.sort_values(by=['TRIP_ID', 'TIMESTAMP'])\n",
    "\n",
    "    df['TIMESTAMP'] = pd.to_datetime(df['TIMESTAMP'], unit='s')\n",
    "    df = df.rename(columns={'TIMESTAMP': 'ds', coord: 'y', 'TRIP_ID': 'unique_id'})\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    df['y'] = scaler.fit_transform(df[['y']])\n",
    "\n",
    "    train_dataset, val_dataset = prepare_datasets(\n",
    "        df=df,\n",
    "        context_length=context_len,\n",
    "        horizon_length=horizon_len,\n",
    "        column='y',\n",
    "        train_split=0.5,\n",
    "    )\n",
    "\n",
    "    print(f\"Created datasets for {coord}:\")\n",
    "    print(f\"- Training samples: {len(train_dataset)}\")\n",
    "    print(f\"- Validation samples: {len(val_dataset)}\")\n",
    "    print(f\"- Using frequency type: {freq_type}\")\n",
    "    return train_dataset, val_dataset, scaler\n",
    "\n",
    "\n",
    "def single_gpu_example(coord: str):\n",
    "    \"\"\"Basic example of finetuning TimesFM on stock data.\"\"\"\n",
    "    model, hparams, tfm_config = get_model(load_weights=True)\n",
    "    config = FinetuningConfig(batch_size=256,\n",
    "                              num_epochs=5,\n",
    "                              learning_rate=1e-4,\n",
    "                              use_wandb=False,\n",
    "                              freq_type=1,\n",
    "                              log_every_n_steps=10,\n",
    "                              val_check_interval=0.5,\n",
    "                              use_quantile_loss=True)\n",
    "\n",
    "    train_dataset, val_dataset, scaler = get_data(128,\n",
    "                                             tfm_config.horizon_len,\n",
    "                                             coord,\n",
    "                                             freq_type=config.freq_type)\n",
    "    finetuner = TimesFMFinetuner(model, config)\n",
    "\n",
    "    print(\"\\nStarting finetuning...\")\n",
    "    results = finetuner.finetune(train_dataset=train_dataset,\n",
    "                                 val_dataset=val_dataset)\n",
    "\n",
    "    print(\"\\nFinetuning completed!\")\n",
    "    print(f\"Training history: {len(results['history']['train_loss'])} epochs\")\n",
    "    print(results)\n",
    "\n",
    "    # plot_predictions(\n",
    "    #     model=model,\n",
    "    #     val_dataset=val_dataset,\n",
    "    # )\n",
    "\n",
    "    torch.save(model.state_dict(), f\"my_finetuned_timesfm/timesfm_predictions_{coord}.ckpt\")\n",
    "    joblib.dump(scaler, f\"my_finetuned_timesfm/scaler_{coord}.pkl\")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def quantile_loss(pred, target, quantiles=None):\n",
    "    \"\"\"\n",
    "    pred: [batch, horizon, num_quantiles]\n",
    "    target: [batch, horizon, 1]\n",
    "    \"\"\"\n",
    "    if quantiles is None:\n",
    "        quantiles = [0.1, 0.5, 0.9]\n",
    "    losses = []\n",
    "    for i, q in enumerate(quantiles):\n",
    "        err = target - pred[..., i:i+1]\n",
    "        losses.append(torch.max((q - 1) * err, q * err).mean())\n",
    "    return sum(losses) / len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T12:08:32.983069Z",
     "start_time": "2025-09-21T12:08:12.355583Z"
    }
   },
   "source": "single_gpu_example(\"LAT\")",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "343917a963d342cebc08809efc495d2c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d1fa55f31b84364b343074e0b02cd48"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created datasets for LAT:\n",
      "- Training samples: 378\n",
      "- Validation samples: 378\n",
      "- Using frequency type: 1\n",
      "\n",
      "Starting finetuning...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m single_gpu_example(\u001B[33m\"\u001B[39m\u001B[33mLAT\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 52\u001B[39m, in \u001B[36msingle_gpu_example\u001B[39m\u001B[34m(coord)\u001B[39m\n\u001B[32m     49\u001B[39m finetuner = TimesFMFinetuner(model, config)\n\u001B[32m     51\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mStarting finetuning...\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m52\u001B[39m results = finetuner.finetune(train_dataset=train_dataset,\n\u001B[32m     53\u001B[39m                              val_dataset=val_dataset)\n\u001B[32m     55\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mFinetuning completed!\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     56\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mTraining history: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(results[\u001B[33m'\u001B[39m\u001B[33mhistory\u001B[39m\u001B[33m'\u001B[39m][\u001B[33m'\u001B[39m\u001B[33mtrain_loss\u001B[39m\u001B[33m'\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m epochs\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\anaconda3\\envs\\taxi-torch\\Lib\\site-packages\\finetuning\\finetuning_torch.py:367\u001B[39m, in \u001B[36mTimesFMFinetuner.finetune\u001B[39m\u001B[34m(self, train_dataset, val_dataset)\u001B[39m\n\u001B[32m    365\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    366\u001B[39m   \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m.config.num_epochs):\n\u001B[32m--> \u001B[39m\u001B[32m367\u001B[39m     train_loss = \u001B[38;5;28mself\u001B[39m._train_epoch(train_loader, optimizer)\n\u001B[32m    368\u001B[39m     val_loss = \u001B[38;5;28mself\u001B[39m._validate(val_loader)\n\u001B[32m    369\u001B[39m     current_lr = optimizer.param_groups[\u001B[32m0\u001B[39m][\u001B[33m\"\u001B[39m\u001B[33mlr\u001B[39m\u001B[33m\"\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\anaconda3\\envs\\taxi-torch\\Lib\\site-packages\\finetuning\\finetuning_torch.py:295\u001B[39m, in \u001B[36mTimesFMFinetuner._train_epoch\u001B[39m\u001B[34m(self, train_loader, optimizer)\u001B[39m\n\u001B[32m    292\u001B[39m num_batches = \u001B[38;5;28mlen\u001B[39m(train_loader)\n\u001B[32m    294\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[32m--> \u001B[39m\u001B[32m295\u001B[39m   loss, _ = \u001B[38;5;28mself\u001B[39m._process_batch(batch)\n\u001B[32m    297\u001B[39m   optimizer.zero_grad()\n\u001B[32m    298\u001B[39m   loss.backward()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\anaconda3\\envs\\taxi-torch\\Lib\\site-packages\\finetuning\\finetuning_torch.py:260\u001B[39m, in \u001B[36mTimesFMFinetuner._process_batch\u001B[39m\u001B[34m(self, batch)\u001B[39m\n\u001B[32m    251\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_process_batch\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch: List[torch.Tensor]) -> \u001B[38;5;28mtuple\u001B[39m:\n\u001B[32m    252\u001B[39m \u001B[38;5;250m  \u001B[39m\u001B[33;03m\"\"\"Process a single batch of data.\u001B[39;00m\n\u001B[32m    253\u001B[39m \n\u001B[32m    254\u001B[39m \u001B[33;03m      Args:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    258\u001B[39m \u001B[33;03m        Tuple of (loss, predictions).\u001B[39;00m\n\u001B[32m    259\u001B[39m \u001B[33;03m      \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m260\u001B[39m   x_context, x_padding, freq, x_future = [\n\u001B[32m    261\u001B[39m       t.to(\u001B[38;5;28mself\u001B[39m.device, non_blocking=\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m batch\n\u001B[32m    262\u001B[39m   ]\n\u001B[32m    264\u001B[39m   predictions = \u001B[38;5;28mself\u001B[39m.model(x_context, x_padding.float(), freq)\n\u001B[32m    265\u001B[39m   predictions_mean = predictions[..., \u001B[32m0\u001B[39m]\n",
      "\u001B[31mValueError\u001B[39m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# single_gpu_example(\"LON\")",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timesfm-DnAbSweh-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
